{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/jovyan/.local/lib/python3.6/site-packages (4.3.0.36)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.16.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/jovyan/.venv/torch1.4.0-py3.6-cuda10.1/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Processing /home/jovyan/.cache/pip/wheels/ea/bb/c4/f45d62d3f68968af6f00e44db92994be9053be3923f73c7c82/dlib-19.21.0-cp36-cp36m-linux_x86_64.whl\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.21.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/jovyan/.venv/torch1.4.0-py3.6-cuda10.1/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Processing /home/jovyan/.cache/pip/wheels/27/4d/3a/6dcdf7c3ebc87bf1ae013d96c9cf060ccfe334bb5ee769f377/imutils-0.5.3-py3-none-any.whl\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.3\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/jovyan/.venv/torch1.4.0-py3.6-cuda10.1/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting torch-mtcnn\n",
      "  Using cached torch_mtcnn-0.0.7-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-mtcnn) (1.16.4)\n",
      "Requirement already satisfied: torchvision in /home/jovyan_venv/.venv/torch1.4.0-py3.6-cuda10.1/lib/python3.6/site-packages (from torch-mtcnn) (0.5.0)\n",
      "Requirement already satisfied: torch in /home/jovyan_venv/.venv/torch1.4.0-py3.6-cuda10.1/lib/python3.6/site-packages (from torch-mtcnn) (1.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->torch-mtcnn) (1.15.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->torch-mtcnn) (7.2.0)\n",
      "Installing collected packages: torch-mtcnn\n",
      "Successfully installed torch-mtcnn-0.0.7\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/home/jovyan/.venv/torch1.4.0-py3.6-cuda10.1/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install dlib\n",
    "!pip install imutils\n",
    "!pip install torch-mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/python36.zip\n",
      "/usr/lib/python3.6\n",
      "/usr/lib/python3.6/lib-dynload\n",
      "\n",
      "/home/jovyan/.venv/torch1.5.1-py3.6-cuda10.1/lib/python3.6/site-packages\n",
      "/home/jovyan/.local/lib/python3.6/site-packages\n",
      "/usr/local/lib/python3.6/dist-packages\n",
      "/usr/lib/python3/dist-packages\n",
      "/usr/local/lib/python3.6/dist-packages/IPython/extensions\n",
      "/home/jovyan/.ipython\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "# import dlib\n",
    "# from imutils import face_utils\n",
    "import sys\n",
    "import os\n",
    "from torch_mtcnn import detect_faces\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "for p in sys.path:\n",
    "    print(p)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/jovyan/cs470-deep-face-classifier/new_data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['태연', '송중기', '박보영', '손예진', '엑소 백현', '아이유', '한효주', '임시완', '워너원 강다니엘', '박보검']\n",
      "['이나영', '유인영', '이준기', '한채영', '김희선', '워너원 황민현', '강동원', '한예슬', '엑소 시우민', '이종석']\n",
      "['마동석', '박성웅', '곽도원', '정형돈', '조진웅', '안재홍', '조세호', '스윙스', '최자', '김구라']\n",
      "['한지민', '육성재', '김아중', '김우빈', '윤두준', '공유', '이민기', '천우희', '신민아', '송지효']\n",
      "['Bald']\n",
      "['이세영', '트와이스 나연', '방탄소년단 정국', '수지', '안형섭', '워너원 박지훈', '트와이스 다현', '아이콘 바비', '백진희', '엑소 수호']\n"
     ]
    }
   ],
   "source": [
    "for i in ['dog','cat', 'bear', 'dinosaur', 'bald', 'rabbit']:\n",
    "    file_path_i = file_path + i\n",
    "    filenames_i = os.listdir(file_path_i)\n",
    "    print(filenames_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here12\n",
      "in for loop\n",
      "in for loop\n"
     ]
    }
   ],
   "source": [
    "for i in ['dog','cat', 'bear', 'dinosaur', 'rabbit']:\n",
    "    file_path_i = file_path + i\n",
    "    filenames_i = os.listdir(file_path_i)\n",
    "    try:\n",
    "        os.mkdir('/home/jovyan/cs470-deep-face-classifier/new_data/updated/'+i)\n",
    "    except:\n",
    "        pass\n",
    "    for j in filenames_i:\n",
    "        file_path_j = file_path_i + '/'+j\n",
    "        files = os.listdir(file_path_j)\n",
    "        try:\n",
    "            os.mkdir('/home/jovyan/cs470-deep-face-classifier/new_data/updated/'+i+'/'+j)\n",
    "        except:\n",
    "            continue\n",
    "        m=1\n",
    "        for k in files:\n",
    "            src = file_path_j + '/' + k\n",
    "            try:\n",
    "                img = Image.open(src)\n",
    "                bounding_boxes, landmarks = detect_faces(img)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            if len(bounding_boxes) != 1:\n",
    "                continue\n",
    "            \n",
    "            x, y, width, height, _ = bounding_boxes[0]\n",
    "            im = np.array(img)\n",
    "            convert  = im[int(y):int(height),int(x):int(width)]\n",
    "            dst = '/home/jovyan/cs470-deep-face-classifier/new_data/updated/'+i+'/'+j+'/'+str(m)+'.jpg'\n",
    "            try:\n",
    "                gr_im= Image.fromarray(convert).save(dst)\n",
    "            except:\n",
    "                continue\n",
    "            m += 1\n",
    "\n",
    "\n",
    "\n",
    "i = 'bald'\n",
    "\n",
    "file_path_i = file_path + i\n",
    "filenames_i = os.listdir(file_path_i)\n",
    "\n",
    "try:\n",
    "    os.mkdir('/home/jovyan/cs470-deep-face-classifier/new_data/updated/'+i)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for j in filenames_i:\n",
    "    file_path_j = file_path_i + '/'+j\n",
    "    files = os.listdir(file_path_j)\n",
    "    try:\n",
    "        os.mkdir('/home/jovyan/cs470-deep-face-classifier/new_data/updated/'+i+'/'+j)\n",
    "    except:\n",
    "        continue\n",
    "    m=1\n",
    "    for k in files:\n",
    "        if m == 3600:\n",
    "            break\n",
    "        src = file_path_j + '/' + k\n",
    "        try:\n",
    "            img = Image.open(src)\n",
    "            bounding_boxes, landmarks = detect_faces(img)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if len(bounding_boxes) != 1:\n",
    "            continue\n",
    "\n",
    "        x, y, width, height, _ = bounding_boxes[0]\n",
    "        im = np.array(img)\n",
    "        convert  = im[int(y):int(height),int(x):int(width)]\n",
    "        dst = '/home/jovyan/cs470-deep-face-classifier/new_data/updated/'+i+'/'+j+'/'+str(m)+'.jpg'\n",
    "        try:\n",
    "            gr_im= Image.fromarray(convert).save(dst)\n",
    "        except:\n",
    "            continue\n",
    "        m += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-507f9ba6985f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_faces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# load the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/torch1.5.1-py3.6-cuda10.1/lib/python3.6/site-packages/torch_mtcnn/detector.py\u001b[0m in \u001b[0;36mdetect_faces\u001b[0;34m(image, min_face_size, thresholds, nms_thresholds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# run P-Net on different scales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscales\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_first_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mbounding_boxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.venv/torch1.5.1-py3.6-cuda10.1/lib/python3.6/site-packages/torch_mtcnn/first_stage.py\u001b[0m in \u001b[0;36mrun_first_stage\u001b[0;34m(image, net, scale, threshold)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# probs: probability of a face at each sliding window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert CUDA tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "path = '/home/jovyan/cs470-deep-face-classifier/datas/raw/dog/엑소 디오/51.jpg'\n",
    "\n",
    "img = Image.open(path)\n",
    "\n",
    "bounding_boxes, landmarks = detect_faces(img)\n",
    "\n",
    "# load the image\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "x, y, width, height, _ = bounding_boxes[0]\n",
    "\n",
    "rect = plt.Rectangle((x, y), width-x, height-y, fill=False, color='green')\n",
    "\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(bounding_boxes)\n",
    "im = np.array(img)\n",
    "print(im.shape)\n",
    "\n",
    "convert  = im[int(y):int(height),int(x):int(width)]\n",
    "gr_im= Image.fromarray(convert).save('/home/jovyan/cs470-deep-face-classifier/new_data/updated/dog/1.jpg')\n",
    "\n",
    "print(convert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1.5.1-py3.6-cuda10.1",
   "language": "python",
   "name": "torch1.5.1-py3.6-cuda10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
