Loaded pretrained weights for efficientnet-b4
Epoch [0]/[100] train_loss: 0.200302 valid_loss: 0.811774 valid_acc:0.349683 valid_precision:0.278677 valid_recall:0.520745 valid_f1:0.363061
Epoch [1]/[100] train_loss: 0.190043 valid_loss: 0.299278 valid_acc:0.517888 valid_precision:0.349088 valid_recall:0.516725 valid_f1:0.416678
Epoch [2]/[100] train_loss: 0.169547 valid_loss: 0.112503 valid_acc:0.811887 valid_precision:0.585154 valid_recall:0.768333 valid_f1:0.664348
Epoch [3]/[100] train_loss: 0.159353 valid_loss: 0.090680 valid_acc:0.787074 valid_precision:0.595384 valid_recall:0.832339 valid_f1:0.694198
Epoch [4]/[100] train_loss: 0.153948 valid_loss: 0.137161 valid_acc:0.864974 valid_precision:0.626262 valid_recall:0.712217 valid_f1:0.666480
Epoch [5]/[100] train_loss: 0.150291 valid_loss: 0.147071 valid_acc:0.859204 valid_precision:0.592138 valid_recall:0.683065 valid_f1:0.634360
Epoch [6]/[100] train_loss: 0.151114 valid_loss: 0.106387 valid_acc:0.864108 valid_precision:0.654048 valid_recall:0.790116 valid_f1:0.715672
Epoch [7]/[100] train_loss: 0.147831 valid_loss: 0.112743 valid_acc:0.866994 valid_precision:0.652994 valid_recall:0.762506 valid_f1:0.703514
Epoch [8]/[100] train_loss: 0.144350 valid_loss: 0.125206 valid_acc:0.872764 valid_precision:0.657612 valid_recall:0.738275 valid_f1:0.695613
Epoch [9]/[100] train_loss: 0.143834 valid_loss: 0.103978 valid_acc:0.871610 valid_precision:0.662646 valid_recall:0.772082 valid_f1:0.713190
Epoch [10]/[100] train_loss: 0.142035 valid_loss: 0.088981 valid_acc:0.875938 valid_precision:0.680871 valid_recall:0.815409 valid_f1:0.742091
Epoch [11]/[100] train_loss: 0.140033 valid_loss: 0.084508 valid_acc:0.875938 valid_precision:0.686132 valid_recall:0.841406 valid_f1:0.755877
Epoch [12]/[100] train_loss: 0.135615 valid_loss: 0.092793 valid_acc:0.874495 valid_precision:0.681264 valid_recall:0.830158 valid_f1:0.748377
Epoch [13]/[100] train_loss: 0.136036 valid_loss: 0.108575 valid_acc:0.862089 valid_precision:0.642693 valid_recall:0.763499 valid_f1:0.697907
Epoch [14]/[100] train_loss: 0.130699 valid_loss: 0.089635 valid_acc:0.793999 valid_precision:0.602678 valid_recall:0.840354 valid_f1:0.701942
Epoch [15]/[100] train_loss: 0.136392 valid_loss: 0.095236 valid_acc:0.874784 valid_precision:0.674692 valid_recall:0.798177 valid_f1:0.731258
Epoch [16]/[100] train_loss: 0.129635 valid_loss: 0.092238 valid_acc:0.882574 valid_precision:0.691326 valid_recall:0.805483 valid_f1:0.744051
Epoch [17]/[100] train_loss: 0.130503 valid_loss: 0.077375 valid_acc:0.864686 valid_precision:0.674223 valid_recall:0.858048 valid_f1:0.755109
Epoch [18]/[100] train_loss: 0.129533 valid_loss: 0.131808 valid_acc:0.865263 valid_precision:0.627580 valid_recall:0.718060 valid_f1:0.669778
Epoch [19]/[100] train_loss: 0.126574 valid_loss: 0.088496 valid_acc:0.862954 valid_precision:0.668775 valid_recall:0.844937 valid_f1:0.746606
Epoch [20]/[100] train_loss: 0.125860 valid_loss: 0.086940 valid_acc:0.864108 valid_precision:0.664799 valid_recall:0.826377 valid_f1:0.736834
Epoch [21]/[100] train_loss: 0.126919 valid_loss: 0.086061 valid_acc:0.892672 valid_precision:0.714615 valid_recall:0.823087 valid_f1:0.765025
Epoch [22]/[100] train_loss: 0.124837 valid_loss: 0.087355 valid_acc:0.892095 valid_precision:0.712878 valid_recall:0.809332 valid_f1:0.758049
Epoch [23]/[100] train_loss: 0.124128 valid_loss: 0.113100 valid_acc:0.888921 valid_precision:0.705158 valid_recall:0.771069 valid_f1:0.736642
Epoch [24]/[100] train_loss: 0.121342 valid_loss: 0.080047 valid_acc:0.875649 valid_precision:0.686116 valid_recall:0.843961 valid_f1:0.756896
Epoch [25]/[100] train_loss: 0.120869 valid_loss: 0.110210 valid_acc:0.882574 valid_precision:0.687754 valid_recall:0.778853 valid_f1:0.730474
Epoch [26]/[100] train_loss: 0.119488 valid_loss: 0.095956 valid_acc:0.890364 valid_precision:0.708395 valid_recall:0.792945 valid_f1:0.748289
Epoch [27]/[100] train_loss: 0.120534 valid_loss: 0.098326 valid_acc:0.894114 valid_precision:0.718863 valid_recall:0.789838 valid_f1:0.752681
Epoch [28]/[100] train_loss: 0.117995 valid_loss: 0.114999 valid_acc:0.888921 valid_precision:0.706783 valid_recall:0.757150 valid_f1:0.731100
Epoch [29]/[100] train_loss: 0.118580 valid_loss: 0.124577 valid_acc:0.881420 valid_precision:0.681247 valid_recall:0.741906 valid_f1:0.710283
Epoch [30]/[100] train_loss: 0.116527 valid_loss: 0.095864 valid_acc:0.886901 valid_precision:0.701425 valid_recall:0.815402 valid_f1:0.754131
Epoch [31]/[100] train_loss: 0.114883 valid_loss: 0.085994 valid_acc:0.894403 valid_precision:0.718589 valid_recall:0.823212 valid_f1:0.767351
Epoch [32]/[100] train_loss: 0.115737 valid_loss: 0.087743 valid_acc:0.896999 valid_precision:0.725151 valid_recall:0.815041 valid_f1:0.767473
Epoch [33]/[100] train_loss: 0.114376 valid_loss: 0.080614 valid_acc:0.879977 valid_precision:0.692381 valid_recall:0.840852 valid_f1:0.759428
Epoch [34]/[100] train_loss: 0.111960 valid_loss: 0.073203 valid_acc:0.861512 valid_precision:0.673361 valid_recall:0.869074 valid_f1:0.758801
Epoch [35]/[100] train_loss: 0.114391 valid_loss: 0.087564 valid_acc:0.889498 valid_precision:0.707553 valid_recall:0.821442 valid_f1:0.760256
Epoch [36]/[100] train_loss: 0.110424 valid_loss: 0.075068 valid_acc:0.860069 valid_precision:0.667157 valid_recall:0.853837 valid_f1:0.749041
Epoch [37]/[100] train_loss: 0.111356 valid_loss: 0.112522 valid_acc:0.897288 valid_precision:0.728795 valid_recall:0.792139 valid_f1:0.759148
Epoch [38]/[100] train_loss: 0.112529 valid_loss: 0.108562 valid_acc:0.895845 valid_precision:0.725295 valid_recall:0.786525 valid_f1:0.754670
Epoch [39]/[100] train_loss: 0.110215 valid_loss: 0.081829 valid_acc:0.892095 valid_precision:0.713763 valid_recall:0.830085 valid_f1:0.767541
Epoch [40]/[100] train_loss: 0.107416 valid_loss: 0.094591 valid_acc:0.895268 valid_precision:0.721164 valid_recall:0.803243 valid_f1:0.759994
Epoch [41]/[100] train_loss: 0.108607 valid_loss: 0.066172 valid_acc:0.872187 valid_precision:0.689815 valid_recall:0.880183 valid_f1:0.773458
Epoch [42]/[100] train_loss: 0.106118 valid_loss: 0.100205 valid_acc:0.892672 valid_precision:0.716550 valid_recall:0.776847 valid_f1:0.745481
Epoch [43]/[100] train_loss: 0.107110 valid_loss: 0.079000 valid_acc:0.907098 valid_precision:0.750397 valid_recall:0.834639 valid_f1:0.790280
Epoch [44]/[100] train_loss: 0.105394 valid_loss: 0.074715 valid_acc:0.863531 valid_precision:0.669541 valid_recall:0.846848 valid_f1:0.747829
Epoch [45]/[100] train_loss: 0.106613 valid_loss: 0.078215 valid_acc:0.896999 valid_precision:0.724797 valid_recall:0.834497 valid_f1:0.775788
Epoch [46]/[100] train_loss: 0.105276 valid_loss: 0.079351 valid_acc:0.897865 valid_precision:0.726849 valid_recall:0.836781 valid_f1:0.777951
Epoch [47]/[100] train_loss: 0.101013 valid_loss: 0.071365 valid_acc:0.879688 valid_precision:0.694344 valid_recall:0.852826 valid_f1:0.765468
Epoch [48]/[100] train_loss: 0.102873 valid_loss: 0.094230 valid_acc:0.906520 valid_precision:0.751305 valid_recall:0.820827 valid_f1:0.784529
Epoch [49]/[100] train_loss: 0.103049 valid_loss: 0.077714 valid_acc:0.903924 valid_precision:0.740684 valid_recall:0.848203 valid_f1:0.790805
Epoch [50]/[100] train_loss: 0.102874 valid_loss: 0.075263 valid_acc:0.897288 valid_precision:0.726005 valid_recall:0.850499 valid_f1:0.783336
Epoch [51]/[100] train_loss: 0.100964 valid_loss: 0.088784 valid_acc:0.905943 valid_precision:0.748866 valid_recall:0.824979 valid_f1:0.785082
Epoch [52]/[100] train_loss: 0.099900 valid_loss: 0.089453 valid_acc:0.903635 valid_precision:0.743692 valid_recall:0.815185 valid_f1:0.777799
Epoch [53]/[100] train_loss: 0.101457 valid_loss: 0.083663 valid_acc:0.900173 valid_precision:0.732762 valid_recall:0.825368 valid_f1:0.776313
Epoch [54]/[100] train_loss: 0.100127 valid_loss: 0.107170 valid_acc:0.898153 valid_precision:0.732296 valid_recall:0.789932 valid_f1:0.760022
Epoch [55]/[100] train_loss: 0.097904 valid_loss: 0.091670 valid_acc:0.903058 valid_precision:0.741775 valid_recall:0.815892 valid_f1:0.777070
Epoch [56]/[100] train_loss: 0.096224 valid_loss: 0.082051 valid_acc:0.904501 valid_precision:0.742852 valid_recall:0.837371 valid_f1:0.787285
Epoch [57]/[100] train_loss: 0.095211 valid_loss: 0.067317 valid_acc:0.892960 valid_precision:0.719348 valid_recall:0.868581 valid_f1:0.786952
Epoch [58]/[100] train_loss: 0.094520 valid_loss: 0.077174 valid_acc:0.899308 valid_precision:0.730252 valid_recall:0.847883 valid_f1:0.784683
Epoch [59]/[100] train_loss: 0.094661 valid_loss: 0.071879 valid_acc:0.899308 valid_precision:0.730611 valid_recall:0.858308 valid_f1:0.789328
Epoch [60]/[100] train_loss: 0.096772 valid_loss: 0.081432 valid_acc:0.899019 valid_precision:0.729522 valid_recall:0.831671 valid_f1:0.777255
Epoch [61]/[100] train_loss: 0.095930 valid_loss: 0.076324 valid_acc:0.905366 valid_precision:0.743899 valid_recall:0.856816 valid_f1:0.796375
Epoch [62]/[100] train_loss: 0.095543 valid_loss: 0.075443 valid_acc:0.890941 valid_precision:0.713643 valid_recall:0.852803 valid_f1:0.777041
Epoch [63]/[100] train_loss: 0.094945 valid_loss: 0.077949 valid_acc:0.899308 valid_precision:0.730302 valid_recall:0.850526 valid_f1:0.785842
